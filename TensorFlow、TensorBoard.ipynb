{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.測試TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello, TensorFlow!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "sess.run(hello)\n",
    "#print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2.使用GradientDescent計算回歸係數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-0.40208578] [ 0.90925348]\n",
      "20 [-0.10502608] [ 0.42126584]\n",
      "40 [ 0.03420851] [ 0.33891341]\n",
      "60 [ 0.07888795] [ 0.31248707]\n",
      "80 [ 0.09322527] [ 0.30400702]\n",
      "100 [ 0.09782604] [ 0.30128583]\n",
      "120 [ 0.09930238] [ 0.30041263]\n",
      "140 [ 0.09977613] [ 0.30013242]\n",
      "160 [ 0.09992817] [ 0.30004251]\n",
      "180 [ 0.09997696] [ 0.30001363]\n",
      "200 [ 0.09999262] [ 0.30000439]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "w = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "#tf.zeros([1]) 一次生成一個 tf.zeros([1,10]) [0], [0], ...[0] #\n",
    "y = w * x_data + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = 0.5)\n",
    "train = opt.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step ,sess.run(w), sess.run(b))\n",
    "\n",
    "\n",
    "#sess.run(train)\n",
    "#print(sess.run(w), sess.run(b))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.比較線性迴歸尋找回歸係數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1]]\n",
      "[ 0.30000004]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(np.reshape(x_data, (len(x_data), 1)), np.reshape(y_data, (len(y_data), 1)))\n",
    "#lm.fit(x_data, y_data)  ~no~\n",
    "print(lm.coef_)\n",
    "\n",
    "print(lm.intercept_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.使用TF進行矩陣計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  6]]\n"
     ]
    }
   ],
   "source": [
    "mat_1 = tf.constant([[1,3]])\n",
    "mat_2 = tf.constant([[2,3],[3,1]])\n",
    "\n",
    "pro = tf.matmul(mat_1, mat_2)\n",
    "\n",
    "\n",
    "#1\n",
    "#sess = tf.Session()\n",
    "\n",
    "#res = sess.run(pro)\n",
    "#print(res)\n",
    "\n",
    "#sess.close()\n",
    "\n",
    "\n",
    "#2\n",
    "#with tf.Session() as sess:\n",
    "#    res = sess.run([pro])\n",
    "#    print(res)\n",
    "\n",
    "\n",
    "#3\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "mat_31 = tf.Variable([[1,3]])\n",
    "mat_32 = tf.Variable([[2,3],\n",
    "                     [3,1]])\n",
    "\n",
    "#mat_31.initializer.run()\n",
    "#mat_32.initializer.run()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "mul = tf.matmul(mat_31, mat_32)\n",
    "print(sess.run(mul))\n",
    "\n",
    "#pro = tf.matmul(mat_31, mat_32)\n",
    "#print(pro.eval())\n",
    "\n",
    "sess.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "state = tf.Variable(0, name = \"counter\")\n",
    "\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "state_upda = tf.assign(state, new_value)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(state))\n",
    "    for i in range(3):\n",
    "        print(sess.run(state_upda))\n",
    "    \n",
    "\n",
    "\n",
    "#sess = tf.Session()\n",
    "#sess.run(init)\n",
    "#for i in range(20):\n",
    "#    print(sess.run(state_upda))\n",
    "#    print(sess.run(state))\n",
    "#sess.close()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.變數輸入與輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([10], dtype=int32), array([21], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "input_1 = tf.placeholder(tf.float32)\n",
    "input_2 = tf.placeholder(tf.float32)\n",
    "\n",
    "input_1 = tf.constant([3])\n",
    "input_2 = tf.constant([7])\n",
    "\n",
    "add = tf.add(input_1, input_2)\n",
    "mul = tf.multiply(input_1, input_2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([add, mul]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "#    print(sess.run([mul], feed_dict = {input_1: [7], input_2: [3]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "嘗試寫隱藏層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.246841\n",
      "0.0205885\n",
      "0.00506145\n",
      "0.00124511\n",
      "0.000306352\n",
      "7.5381e-05\n",
      "1.85469e-05\n",
      "4.56456e-06\n",
      "1.12296e-06\n",
      "2.76382e-07\n"
     ]
    }
   ],
   "source": [
    "def add_layer(input_data, input_tensors, outpt_tensors, activation_function = None):\n",
    "    w = tf.Variable(tf.random_normal([input_tensors, outpt_tensors]))\n",
    "    b = tf.Variable(tf.zeros([1, outpt_tensors]))\n",
    "    formu = tf.add(tf.matmul(input_data, w), b)\n",
    "    if activation_function is None:\n",
    "        output = formu\n",
    "    else:\n",
    "        output = activation_function(formu)\n",
    "    return output        \n",
    "\n",
    "\n",
    "x_data = np.random.rand(100)\n",
    "x_data = x_data.reshape(len(x_data), 1)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "x_feeds = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "y_feeds = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "hidden_layer = add_layer(x_feeds, input_tensors = 1, outpt_tensors = 10, activation_function = None)\n",
    "outer_layer  = add_layer(hidden_layer, input_tensors = 10, outpt_tensors = 1, activation_function = None)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y_feeds - outer_layer))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "tra_res = opt.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(190):\n",
    "    sess.run(tra_res, feed_dict= {x_feeds: x_data, y_feeds: y_data})\n",
    "    if i % 20 == 0:\n",
    "        print(sess.run(loss, feed_dict = {x_feeds: x_data, y_feeds: y_data}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用tensorboard將之視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762244\n",
      "0.0212164\n",
      "0.0123959\n",
      "0.00726598\n",
      "0.00426266\n",
      "0.00250209\n",
      "0.00146919\n",
      "0.000862887\n",
      "0.000506871\n",
      "0.000297778\n"
     ]
    }
   ],
   "source": [
    "def add_layer(input_data, input_tensors, outpt_tensors, activation_function = None):\n",
    "    with tf.name_scope('Layer'):\n",
    "        with tf.name_scope('Weights'):\n",
    "            w = tf.Variable(tf.random_normal([input_tensors, outpt_tensors]))\n",
    "        with tf.name_scope('Biases'):\n",
    "            b = tf.Variable(tf.zeros([1, outpt_tensors]))\n",
    "        with tf.name_scope('Formula'):\n",
    "            formu = tf.add(tf.matmul(input_data, w), b)\n",
    "        if activation_function is None:\n",
    "            output = formu\n",
    "        else:\n",
    "            output = activation_function(formu)\n",
    "        return output        \n",
    "\n",
    "x_data = np.random.rand(100)\n",
    "x_data = x_data.reshape(len(x_data), 1)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "with tf.name_scope('Feeds'):\n",
    "    x_feeds = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "    y_feeds = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "hidden_layer = add_layer(x_feeds, input_tensors = 1, outpt_tensors = 10, activation_function = None)\n",
    "outer_layer  = add_layer(hidden_layer, input_tensors = 10, outpt_tensors = 1, activation_function = None)\n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "    loss = tf.reduce_mean(tf.square(y_feeds - outer_layer))\n",
    "with tf.name_scope('Train'):\n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "    tra_res = opt.minimize(loss)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "write = tf.summary.FileWriter(\"TensorBoard/\", graph = sess.graph)\n",
    "\n",
    "for i in range(190):\n",
    "    sess.run(tra_res, feed_dict= {x_feeds: x_data, y_feeds: y_data})\n",
    "    if i % 20 == 0:\n",
    "        print(sess.run(loss, feed_dict = {x_feeds: x_data, y_feeds: y_data}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "! pip3 install tensorboard、localhost:6006、Tingde-MacBook-Pro:pythonjupyter ting$ tensorboard --logdir TensorBoard/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "玩mnist資料並建造分類器辨識之"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngQAgIRAAJAQCgIRAAJD8H4pTI02QaexyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13aa83240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist  = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_tra  = mnist.train.images\n",
    "y_tra  = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "#print(x_tra[1,:])\n",
    "\n",
    "print(np.argmax(y_tra[1,:], axis = 0))\n",
    "\n",
    "first_tra_img = np.reshape(x_tra[1, :], (28, 28))\n",
    "plt.matshow(first_tra_img,cmap = plt.get_cmap('Reds'))\n",
    "plt.show()\n",
    "\n",
    "#理解資料型態＃\n",
    "'''\n",
    "type(y_tra)\n",
    "type(x_tra)\n",
    "np.shape(y_tra)\n",
    "np.shape(x_tra)\n",
    "y_tra[1,:]\n",
    "first_tra_img = np.reshape(x_tra[1, :], (28, 28))\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "1.67311\n",
      "0.356003\n",
      "0.386282\n",
      "0.432872\n",
      "0.355879\n",
      "0.225063\n",
      "0.311063\n",
      "0.280701\n",
      "0.335932\n",
      "0.161922\n",
      "0.21674\n",
      "0.278052\n",
      "0.365288\n",
      "0.396833\n",
      "0.151868\n",
      "0.216886\n",
      "0.12562\n",
      "0.204515\n",
      "0.188744\n",
      "0.248115\n",
      "---\n",
      "Accuracy:  0.9194\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "training_steps = 1000\n",
    "batch_size = 100\n",
    "logs_path = 'TensorBoard/'\n",
    "n_features = x_train.shape[1]\n",
    "n_labels = y_train.shape[1]\n",
    "\n",
    "\n",
    "with tf.name_scope('Inputs'):\n",
    "    x = tf.placeholder(tf.float32, [None, n_features], name = 'Input_Data')\n",
    "with tf.name_scope('Labels'):\n",
    "    y = tf.placeholder(tf.float32, [None, n_labels], name = 'Label_Data')\n",
    "\n",
    "\n",
    "with tf.name_scope('ModelParameters'):\n",
    "    W = tf.Variable(tf.zeros([n_features, n_labels]), name = 'Weights')\n",
    "    b = tf.Variable(tf.zeros([n_labels]), name = 'Bias')\n",
    "\n",
    "\n",
    "with tf.name_scope('Model'):\n",
    "    prediction = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "with tf.name_scope('CrossEntropy'):\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(prediction), reduction_indices = 1))\n",
    "    tf.summary.scalar(\"Loss\", loss)\n",
    "with tf.name_scope('GradientDescent'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('Accuracy', acc)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(logs_path, graph = tf.get_default_graph())\n",
    "\n",
    "for step in range(training_steps):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    sess.run(optimizer, feed_dict = {x: batch_xs, y: batch_ys})\n",
    "    if step % 50 == 0:\n",
    "        print(sess.run(loss, feed_dict = {x: batch_xs, y: batch_ys}))\n",
    "        summary = sess.run(merged, feed_dict = {x: batch_xs, y: batch_ys})\n",
    "        writer.add_summary(summary, step)\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "print(\"Accuracy: \", sess.run(acc, feed_dict={x: x_test, y: y_test}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
